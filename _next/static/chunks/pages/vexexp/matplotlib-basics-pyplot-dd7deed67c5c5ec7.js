(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[956],{1713:(e,n,t)=>{"use strict";t.d(n,{A:()=>d});var a=t(4232);let s=e=>e.replace(/([a-z0-9])([A-Z])/g,"$1-$2").toLowerCase(),i=e=>e.replace(/^([A-Z])|[\s-_]+(\w)/g,(e,n,t)=>t?t.toUpperCase():n.toLowerCase()),r=e=>{let n=i(e);return n.charAt(0).toUpperCase()+n.slice(1)},l=function(){for(var e=arguments.length,n=Array(e),t=0;t<e;t++)n[t]=arguments[t];return n.filter((e,n,t)=>!!e&&""!==e.trim()&&t.indexOf(e)===n).join(" ").trim()},o=e=>{for(let n in e)if(n.startsWith("aria-")||"role"===n||"title"===n)return!0};var p={xmlns:"http://www.w3.org/2000/svg",width:24,height:24,viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:2,strokeLinecap:"round",strokeLinejoin:"round"};let c=(0,a.forwardRef)((e,n)=>{let{color:t="currentColor",size:s=24,strokeWidth:i=2,absoluteStrokeWidth:r,className:c="",children:d,iconNode:m,...h}=e;return(0,a.createElement)("svg",{ref:n,...p,width:s,height:s,stroke:t,strokeWidth:r?24*Number(i)/Number(s):i,className:l("lucide",c),...!d&&!o(h)&&{"aria-hidden":"true"},...h},[...m.map(e=>{let[n,t]=e;return(0,a.createElement)(n,t)}),...Array.isArray(d)?d:[d]])}),d=(e,n)=>{let t=(0,a.forwardRef)((t,i)=>{let{className:o,...p}=t;return(0,a.createElement)(c,{ref:i,iconNode:n,className:l("lucide-".concat(s(r(e))),"lucide-".concat(e),o),...p})});return t.displayName=r(e),t}},5851:(e,n,t)=>{"use strict";t.d(n,{A:()=>a});let a=(0,t(1713).A)("triangle-alert",[["path",{d:"m21.73 18-8-14a2 2 0 0 0-3.48 0l-8 14A2 2 0 0 0 4 21h16a2 2 0 0 0 1.73-3",key:"wmoenq"}],["path",{d:"M12 9v4",key:"juzpu7"}],["path",{d:"M12 17h.01",key:"p32p05"}]])},6236:(e,n,t)=>{(window.__NEXT_P=window.__NEXT_P||[]).push(["/vexexp/matplotlib-basics-pyplot",function(){return t(8791)}])},6522:(e,n,t)=>{"use strict";t.d(n,{Jr:()=>x,BZ:()=>b,T0:()=>u,Ns:()=>y,w2:()=>_,Q5:()=>f,XF:()=>g});var a=t(7876);t(4232);var s=t(5851),i=t(1713);let r=(0,i.A)("info",[["circle",{cx:"12",cy:"12",r:"10",key:"1mglay"}],["path",{d:"M12 16v-4",key:"1dtifu"}],["path",{d:"M12 8h.01",key:"e9boi3"}]]),l=(0,i.A)("lightbulb",[["path",{d:"M15 14c.2-1 .7-1.7 1.5-2.5 1-.9 1.5-2.2 1.5-3.5A6 6 0 0 0 6 8c0 1 .2 2.2 1.5 3.5.7.7 1.3 1.5 1.5 2.5",key:"1gvzjb"}],["path",{d:"M9 18h6",key:"x1upvd"}],["path",{d:"M10 22h4",key:"ceow96"}]]),o=(0,i.A)("circle-x",[["circle",{cx:"12",cy:"12",r:"10",key:"1mglay"}],["path",{d:"m15 9-6 6",key:"1uzhvr"}],["path",{d:"m9 9 6 6",key:"z0biqf"}]]),p=(0,i.A)("quote",[["path",{d:"M16 3a2 2 0 0 0-2 2v6a2 2 0 0 0 2 2 1 1 0 0 1 1 1v1a2 2 0 0 1-2 2 1 1 0 0 0-1 1v2a1 1 0 0 0 1 1 6 6 0 0 0 6-6V5a2 2 0 0 0-2-2z",key:"rib7q0"}],["path",{d:"M5 3a2 2 0 0 0-2 2v6a2 2 0 0 0 2 2 1 1 0 0 1 1 1v1a2 2 0 0 1-2 2 1 1 0 0 0-1 1v2a1 1 0 0 0 1 1 6 6 0 0 0 6-6V5a2 2 0 0 0-2-2z",key:"1ymkrd"}]]),c=(0,i.A)("circle-check-big",[["path",{d:"M21.801 10A10 10 0 1 1 17 3.335",key:"yps3ct"}],["path",{d:"m9 11 3 3L22 4",key:"1pflzl"}]]),d=(0,i.A)("zap",[["path",{d:"M4 14a1 1 0 0 1-.78-1.63l9.9-10.2a.5.5 0 0 1 .86.46l-1.92 6.02A1 1 0 0 0 13 10h7a1 1 0 0 1 .78 1.63l-9.9 10.2a.5.5 0 0 1-.86-.46l1.92-6.02A1 1 0 0 0 11 14z",key:"1xq2db"}]]),m={warning:{icon:s.A,bgColor:"bg-amber-50",borderColor:"border-l-amber-500",iconColor:"text-amber-600",titleColor:"text-amber-800",defaultTitle:"Warning"},note:{icon:r,bgColor:"bg-blue-50",borderColor:"border-l-blue-500",iconColor:"text-blue-600",titleColor:"text-blue-800",defaultTitle:"Note"},tip:{icon:l,bgColor:"bg-green-50",borderColor:"border-l-green-500",iconColor:"text-green-600",titleColor:"text-green-800",defaultTitle:"Tip"},error:{icon:o,bgColor:"bg-red-50",borderColor:"border-l-red-500",iconColor:"text-red-600",titleColor:"text-red-800",defaultTitle:"Error"},quote:{icon:p,bgColor:"bg-purple-50",borderColor:"border-l-purple-500",iconColor:"text-purple-600",titleColor:"text-purple-800",defaultTitle:"Quote"},success:{icon:c,bgColor:"bg-emerald-50",borderColor:"border-l-emerald-500",iconColor:"text-emerald-600",titleColor:"text-emerald-800",defaultTitle:"Success"},important:{icon:d,bgColor:"bg-orange-50",borderColor:"border-l-orange-500",iconColor:"text-orange-600",titleColor:"text-orange-800",defaultTitle:"Important"}},h=e=>{let{type:n,title:t,children:s,className:i=""}=e,r=m[n],l=r.icon,o=t||r.defaultTitle;return(0,a.jsxs)("div",{className:"\n      flex gap-4 p-4 rounded-lg border-l-4 \n      ".concat(r.bgColor," \n      ").concat(r.borderColor," \n      ").concat(i,"\n    "),children:[(0,a.jsx)("div",{className:"flex-shrink-0",children:(0,a.jsx)(l,{className:"w-6 h-6 ".concat(r.iconColor)})}),(0,a.jsxs)("div",{className:"flex-1 min-w-0",children:[(0,a.jsx)("h4",{className:"font-semibold text-lg mb-2 ".concat(r.titleColor),children:o}),(0,a.jsx)("div",{className:"text-gray-700 leading-relaxed",children:s})]})]})},g=e=>(0,a.jsx)(h,{type:"warning",...e}),u=e=>(0,a.jsx)(h,{type:"note",...e}),f=e=>(0,a.jsx)(h,{type:"tip",...e}),x=e=>(0,a.jsx)(h,{type:"error",...e}),y=e=>(0,a.jsx)(h,{type:"quote",...e}),_=e=>(0,a.jsx)(h,{type:"success",...e}),b=e=>(0,a.jsx)(h,{type:"important",...e})},8791:(e,n,t)=>{"use strict";t.r(n),t.d(n,{default:()=>m});var a=t(7876),s=t(3923),i=t(8144),r=t(6004),l=t(1621),o=t(6522),p=t(9254);let c=function(e){let{children:n}=e;return(0,a.jsx)(i.S,{children:n})};function d(e){let n={a:"a",br:"br",h1:"h1",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,a.jsxs)(r.A,{children:[(0,a.jsx)(n.h1,{children:"MatPlotLib Data Visualization Tutorial for Python 3.13"}),(0,a.jsx)("br",{}),(0,a.jsx)(n.h2,{children:"Table of Contents"}),(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"This article has a lot of content ahead. Below is a table of contents for your convenience:"})}),(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"#battery-life-over-time",children:"Visualizing Battery Life Over Time"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"#what-is-matplotlib",children:"What is MatPlotLib?"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"#why-would-we-use-it",children:"Why MatPlotLib Would be Used"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"#intro-to-plotting",children:"Intro to Plotting"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"#collecting-data",children:"Collecting Data"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"#stat-analysis",children:"Performing Statistical Analysis on Images"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"#summary-next-steps",children:"Summary and Next Steps"})}),"\n"]}),(0,a.jsx)("br",{}),(0,a.jsxs)(n.h2,{children:["Visualizing Battery Life Over Time  ",(0,a.jsx)("a",{id:"battery-life-over-time"})]}),(0,a.jsxs)(n.p,{children:["Before we dive into what MatPlotLib is, let's start with an example that shows why data visualization is so powerful.",(0,a.jsx)("br",{})]}),(0,a.jsx)(n.p,{children:"Imagine you're tracking your phone's battery life throughout the day. You could just look at a list of numbers, but a graph makes patterns\nimmediately obvious:"}),(0,a.jsx)(l.zI,{code:"import matplotlib.pyplot as plt\nimport numpy as np\nfrom datetime import datetime, timedelta\n\n# Sample battery data - imagine this came from monitoring a device\n# Time in hours since midnight\ntime_hours = [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n# Battery percentage at each time\nbattery_percent = [100, 95, 88, 82, 75, 65, 58, 45, 38, 25, 18, 12, 8, 5, 2]\n\n# Create the plot\nplt.figure(figsize=(10, 6))\nplt.plot(time_hours, battery_percent, 'b-o', linewidth=2, markersize=6)\nplt.title('Phone Battery Life Throughout the Day', fontsize=16)\nplt.xlabel('Time (24-hour format)', fontsize=12)\nplt.ylabel('Battery Percentage (%)', fontsize=12)\nplt.grid(True, alpha=0.3)\nplt.ylim(0, 100)\n\n# Add some annotations to highlight interesting points\nplt.annotate('Lunch break - less usage', \n           xy=(12, 75), xytext=(10, 85),\n           arrowprops=dict(arrowstyle='->', color='red'),\n           fontsize=10, color='red')\n\nplt.annotate('Heavy usage period', \n           xy=(16, 38), xytext=(17.5, 50),\n           arrowprops=dict(arrowstyle='->', color='red'),\n           fontsize=10, color='red')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Notice how the graph immediately shows:\")\nprint(\"- Steady battery drain during normal use\")\nprint(\"- Slower drain during lunch (less usage)\")\nprint(\"- Faster drain in the afternoon (heavy usage)\")\nprint(\"- Critical battery levels after 8 PM\")",tooltips:l.M2,theme:"dark",showLineNumbers:!0,copyButton:!0,className:"mb-6"}),(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:"/images/battery_life.png",alt:"image",title:"Plotted line graph displaying the rate of battery life throughout the day"})}),(0,a.jsx)(n.p,{children:"This single graph tells a story that would be hard to see in a table of numbers. That's the power of data visualization! (Note that the data\nisn't really super meaningful, I mainly wanted to show off it having annotation and visualization)"}),(0,a.jsx)("br",{}),(0,a.jsxs)(n.h2,{children:["What is MatPlotLib? ",(0,a.jsx)("a",{id:"what-is-matplotlib"})]}),(0,a.jsxs)(n.p,{children:['MatPlotLib is Python\'s most popular library for creating graphs, charts, and visualizations. Think of it as a digital graphing calculator that\ncan create publication-quality figures. The name comes from "MATLAB plotting library" - it was originally designed to provide MATLAB-like\nplotting capabilities in Python.',(0,a.jsx)("br",{})]}),(0,a.jsxs)(n.p,{children:["MatPlotLib can create virtually any type of 2D plot you can imagine: line graphs, bar charts, scatter plots, histograms, pie charts, and much\nmore. It's used everywhere from scientific research to business analytics to data journalism.",(0,a.jsx)("br",{})]}),(0,a.jsx)(n.p,{children:"The library has two main interfaces:"}),(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"pyplot"})," - Similar to MATLAB, good for simple plots and interactive use"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Object-oriented interface"})," - More powerful and flexible for complex applications",(0,a.jsx)("br",{}),(0,a.jsx)("br",{})]}),"\n"]}),(0,a.jsx)(n.p,{children:"For learning, we'll focus on pyplot since it's more intuitive for beginners."}),(0,a.jsx)("br",{}),(0,a.jsxs)(n.h2,{children:["Why Would We Use It?  ",(0,a.jsx)("a",{id:"why-would-we-use-it"})]}),(0,a.jsx)(n.p,{children:"Data visualization serves several crucial purposes that make it indispensable in data analysis and scientific computing:"}),(0,a.jsx)(n.h3,{children:"1. Pattern Recognition"}),(0,a.jsx)(n.p,{children:"Human brains are incredibly good at recognizing visual patterns. A trend that might be hidden in hundreds of numbers becomes immediately\nobvious when plotted. For example, seasonal patterns in temperature data or cyclical behavior in stock prices."}),(0,a.jsx)(n.h3,{children:"2. Communication"}),(0,a.jsx)(n.p,{children:'"A picture is worth a thousand words" is especially true in data science. A well-designed graph can communicate complex findings to any\naudience, regardless of their technical background. Instead of explaining statistics, you can show the story the data tells.'}),(0,a.jsx)(n.h3,{children:"3. Quality Control"}),(0,a.jsx)(n.p,{children:"Visualizations help you spot problems in your data: outliers, missing values, measurement errors, or unexpected patterns. A scatter plot might\nreveal that your temperature sensor was giving impossible readings, or a time series might show gaps in your data collection."}),(0,a.jsx)(n.h3,{children:"4. Decision Making"}),(0,a.jsx)(n.p,{children:"Graphs help you make informed decisions by presenting data in context. Comparing different options, tracking progress toward goals, or\nidentifying trends all become clearer with visualization."}),(0,a.jsx)(n.h3,{children:"5. Exploration"}),(0,a.jsx)(n.p,{children:"Often, you don't know what questions to ask until you see your data. Interactive plots let you explore relationships, test hypotheses, and\ndiscover unexpected insights."}),(0,a.jsx)("br",{}),(0,a.jsxs)(n.h2,{children:["Intro to Plotting  ",(0,a.jsx)("a",{id:"intro-to-plotting"})]}),(0,a.jsx)(n.p,{children:"Let's start with the fundamental concepts of plotting: axes, data, and how to put them together."}),(0,a.jsx)(n.h3,{children:"Understanding Axes"}),(0,a.jsx)(n.p,{children:"Every plot has at least two axes:"}),(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"X-axis (horizontal)"}),": Usually represents the independent variable - the thing you control or measure first"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Y-axis (vertical)"}),": Usually represents the dependent variable - the thing that changes in response to X",(0,a.jsx)("br",{}),(0,a.jsx)("br",{})]}),"\n"]}),(0,a.jsx)(n.p,{children:"Think of axes as the rulers on the edges of graph paper. They define the scale and units of measurement."}),(0,a.jsx)(n.h3,{children:"Basic Line Plot"}),(0,a.jsx)(n.p,{children:"Line plots show changes and trends in data over time or across different categories:"}),(0,a.jsx)(l.zI,{code:"import matplotlib.pyplot as plt\nimport numpy as np\n\n# Simple example: How does a ball's height change when you drop it?\ntime_seconds = [0, 1, 2, 3, 4]  # Time in seconds\nheight_meters = [10, 8.1, 6.4, 4.9, 3.6]  # Height in meters (with air resistance)\n\n# Create the plot\nplt.figure(figsize=(8, 6))\nplt.plot(time_seconds, height_meters, 'ro-')  # 'ro-' means red circles connected by lines\n\n# Add labels and title\nplt.title('Falling Ball Height Over Time')\nplt.xlabel('Time (seconds)')\nplt.ylabel('Height (meters)')\n\n# Add a grid to make it easier to read values\nplt.grid(True)\n\n# Show the plot\nplt.show()",tooltips:l.M2,theme:"dark",showLineNumbers:!0,copyButton:!0,className:"mb-6"}),(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:"/images/ball_height.png",alt:"image",title:"Plotted line graph displaying the rate of a falling ball's decreasing height over time"})}),(0,a.jsx)(n.h3,{children:"Bar Chart Example"}),(0,a.jsx)(n.p,{children:"Bar charts are great for comparing categories or showing discrete data:"}),(0,a.jsx)(l.zI,{code:"import matplotlib.pyplot as plt\n\n# Example: Test scores in different subjects\nsubjects = ['Math', 'Science', 'English', 'History', 'Art']\nscores = [85, 92, 78, 88, 95]\n\nplt.figure(figsize=(10, 6))\nbars = plt.bar(subjects, scores, color=['blue', 'green', 'red', 'orange', 'purple'])\n\n# Customize the chart\nplt.title('Test Scores by Subject', fontsize=16)\nplt.xlabel('Subject', fontsize=12)\nplt.ylabel('Score (%)', fontsize=12)\nplt.ylim(0, 100)  # Set Y-axis limits\n\n# Add value labels on top of each bar\nfor bar, score in zip(bars, scores):\n  plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n           str(score), ha='center', va='bottom', fontsize=11)\n\nplt.tight_layout()\nplt.show()",tooltips:l.M2,theme:"dark",showLineNumbers:!0,copyButton:!0,className:"mb-6"}),(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:"/images/test_scores.png",alt:"image",title:"Bar chart displaying test scores by subject"})}),(0,a.jsx)(n.h3,{children:"Scatter Plot Example"}),(0,a.jsx)(n.p,{children:"Scatter plots show relationships between two continuous variables:"}),(0,a.jsx)(l.zI,{code:"import matplotlib.pyplot as plt\nimport numpy as np\n\n# Example: Does study time affect test scores?\nstudy_hours = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\ntest_scores = [45, 55, 65, 70, 75, 85, 88, 92, 95, 98]\n\nplt.figure(figsize=(8, 6))\nplt.scatter(study_hours, test_scores, color='blue', s=100, alpha=0.7)\n\n# Add a trend line\nz = np.polyfit(study_hours, test_scores, 1)  # Linear fit\np = np.poly1d(z)\nplt.plot(study_hours, p(study_hours), \"r--\", alpha=0.8, linewidth=2)\n\nplt.title('Study Time vs Test Scores')\nplt.xlabel('Study Hours')\nplt.ylabel('Test Score (%)')\nplt.grid(True, alpha=0.3)\n\n# Add correlation information\ncorrelation = np.corrcoef(study_hours, test_scores)[0,1]\nplt.text(2, 90, f'Correlation: {correlation:.2f}', fontsize=12, \n       bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7))\n\nplt.show()",tooltips:l.M2,theme:"dark",showLineNumbers:!0,copyButton:!0,className:"mb-6"}),(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:"/images/study_vs_test.png",alt:"image",title:"Scatter plot graph showing how study time affects test scores, with an added trend line"})}),(0,a.jsx)(n.h3,{children:"Multiple Data Series"}),(0,a.jsx)(n.p,{children:"Often you want to compare multiple datasets on the same plot:"}),(0,a.jsx)(l.zI,{code:"import matplotlib.pyplot as plt\nimport numpy as np\n\n# Example: Temperature comparison between two cities\nmonths = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n        'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\ncity_a_temps = [32, 38, 48, 58, 68, 78, 85, 83, 76, 65, 50, 38]\ncity_b_temps = [45, 48, 55, 62, 70, 78, 82, 80, 75, 68, 58, 50]\n\nplt.figure(figsize=(12, 6))\nplt.plot(months, city_a_temps, 'b-o', label='City A', linewidth=2, markersize=6)\nplt.plot(months, city_b_temps, 'r-s', label='City B', linewidth=2, markersize=6)\n\nplt.title('Monthly Temperature Comparison', fontsize=16)\nplt.xlabel('Month', fontsize=12)\nplt.ylabel('Average Temperature (\xb0F)', fontsize=12)\nplt.legend(fontsize=12)\nplt.grid(True, alpha=0.3)\n\n# Rotate x-axis labels for better readability\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()",tooltips:l.M2,theme:"dark",showLineNumbers:!0,copyButton:!0,className:"mb-6"}),(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:"/images/monthly_temps.png",alt:"image",title:"Plotted line graph that compares the temperatures of two cities"})}),(0,a.jsx)(n.h3,{children:"Subplots - Multiple Charts in One Figure"}),(0,a.jsx)(n.p,{children:"Sometimes you want to show related charts side by side:"}),(0,a.jsx)(l.zI,{code:"import matplotlib.pyplot as plt\nimport numpy as np\n\n# Create sample data\nx = np.linspace(0, 10, 100)\ny1 = np.sin(x)\ny2 = np.cos(x)\ny3 = np.sin(x) * np.cos(x)\n\n# Create subplots\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n\n# Plot 1\nax1.plot(x, y1, 'b-', linewidth=2)\nax1.set_title('sin(x)')\nax1.set_xlabel('x')\nax1.set_ylabel('y')\nax1.grid(True)\n\n# Plot 2\nax2.plot(x, y2, 'r-', linewidth=2)\nax2.set_title('cos(x)')\nax2.set_xlabel('x')\nax2.set_ylabel('y')\nax2.grid(True)\n\n# Plot 3\nax3.plot(x, y3, 'g-', linewidth=2)\nax3.set_title('sin(x) \xd7 cos(x)')\nax3.set_xlabel('x')\nax3.set_ylabel('y')\nax3.grid(True)\n\nplt.tight_layout()\nplt.show()",tooltips:l.M2,theme:"dark",showLineNumbers:!0,copyButton:!0,className:"mb-6"}),(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:"/images/trig_graphs.png",alt:"image",title:"Multiple line graphs showing trigonometric functions"})}),(0,a.jsx)("br",{}),(0,a.jsxs)(n.h2,{children:["Collecting Data  ",(0,a.jsx)("a",{id:"collecting-data"})]}),(0,a.jsx)(n.p,{children:"Good data visualization starts with good data collection. Here are the key principles and practical techniques for gathering data that will\ncreate meaningful visualizations:"}),(0,a.jsx)(n.h3,{children:"Data Collection Best Practices"}),(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"1. Consistency"}),": Collect data at regular intervals and use consistent units and formats. If you're measuring temperature every hour,\ndon't suddenly switch to every 30 minutes without noting the change."]}),(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"2. Completeness"}),": Missing data points can distort your visualizations. Plan for data collection failures and have strategies for handling\ngaps."]}),(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"3. Accuracy"}),": Ensure your measuring instruments are calibrated and your data entry is error-free. One bad data point can skew an entire\nanalysis."]}),(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"4. Context"}),": Always record when, where, and how data was collected. This metadata helps you interpret results and identify potential issues."]}),(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"5. Real-time vs. Batch"}),": Decide whether you need live updating visualizations or if processing data in batches is sufficient."]}),(0,a.jsx)(n.h3,{children:"Non-blocking Data Collection"}),(0,a.jsx)(n.p,{children:"When collecting data from sensors, cameras, or other real-time sources, you don't want your data collection to stop while creating\nvisualizations. Here's how to handle this:"}),(0,a.jsx)(l.zI,{code:'import matplotlib.pyplot as plt\nimport numpy as np\nimport time\nimport threading\nfrom collections import deque\nimport random\n\nclass DataCollector:\n  def __init__(self, max_points=100):\n      self.data = deque(maxlen=max_points)  # Automatically limits size\n      self.timestamps = deque(maxlen=max_points)\n      self.collecting = False\n      self.thread = None\n  \n  def start_collection(self):\n      """Start collecting data in a separate thread"""\n      self.collecting = True\n      self.thread = threading.Thread(target=self._collect_data)\n      self.thread.daemon = True  # Dies when main program exits\n      self.thread.start()\n      print("Data collection started...")\n  \n  def stop_collection(self):\n      """Stop collecting data"""\n      self.collecting = False\n      if self.thread:\n          self.thread.join()\n      print("Data collection stopped.")\n  \n  def _collect_data(self):\n      """Simulate collecting sensor data"""\n      while self.collecting:\n          # Simulate sensor reading (replace with actual sensor code)\n          sensor_value = 50 + 10 * np.sin(time.time() / 5) + random.gauss(0, 2)\n          \n          # Store data with timestamp\n          self.data.append(sensor_value)\n          self.timestamps.append(time.time())\n          \n          time.sleep(0.1)  # Collect data every 100ms\n  \n  def get_data(self):\n      """Get current data for plotting"""\n      return list(self.timestamps), list(self.data)\n  \n  def plot_current_data(self):\n      """Create a plot of current data"""\n      if len(self.data) < 2:\n          print("Not enough data to plot yet...")\n          return\n      \n      times, values = self.get_data()\n      \n      # Convert timestamps to relative time in seconds\n      start_time = times[0]\n      relative_times = [(t - start_time) for t in times]\n      \n      plt.figure(figsize=(12, 6))\n      plt.plot(relative_times, values, \'b-\', linewidth=2, alpha=0.7)\n      plt.title(\'Real-time Sensor Data\')\n      plt.xlabel(\'Time (seconds)\')\n      plt.ylabel(\'Sensor Value\')\n      plt.grid(True, alpha=0.3)\n      \n      # Add statistics\n      avg_value = np.mean(values)\n      std_value = np.std(values)\n      plt.axhline(y=avg_value, color=\'r\', linestyle=\'--\', alpha=0.7, \n                 label=f\'Average: {avg_value:.1f}\')\n      \n      plt.legend()\n      plt.tight_layout()\n      plt.show()\n\n# Example usage\ndef data_collection_example():\n  collector = DataCollector(max_points=200)\n  \n  try:\n      collector.start_collection()\n      \n      # Let it collect data for a while\n      print("Collecting data for 10 seconds...")\n      time.sleep(10)\n      \n      # Plot the collected data\n      collector.plot_current_data()\n      \n      # Continue collecting and plot again\n      print("Collecting for 10 more seconds...")\n      time.sleep(10)\n      collector.plot_current_data()\n      \n  finally:\n      collector.stop_collection()\n\n# Uncomment to run the example\n# data_collection_example()',tooltips:l.M2,theme:"dark",showLineNumbers:!0,copyButton:!0,className:"mb-6"}),(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:"/images/rts_data.png",alt:"image",title:"Line graph that displays data collected from a sensor"})}),(0,a.jsx)(n.h3,{children:"Reading Data from Files"}),(0,a.jsx)(n.p,{children:"Often you'll want to load data from CSV files or other sources for visualization:"}),(0,a.jsx)(l.zI,{code:'import matplotlib.pyplot as plt\nimport numpy as np\nimport tkinter as tk\nfrom tkinter import filedialog\nimport csv\n\ndef plot_csv_data():\n  """Load and plot data from a CSV file"""\n  root = tk.Tk()\n  root.withdraw()\n  \n  file_path = filedialog.askopenfilename(\n      title="Select a CSV file",\n      filetypes=[("CSV files", "*.csv"), ("All files", "*.*")]\n  )\n  \n  if not file_path:\n      return\n  \n  try:\n      # Read the CSV file\n      with open(file_path, \'r\') as file:\n          csv_reader = csv.reader(file)\n          headers = next(csv_reader)  # First row is headers\n          \n          # Read all data\n          data = []\n          for row in csv_reader:\n              data.append(row)\n      \n      # Convert to numpy array for easier manipulation\n      data_array = np.array(data)\n      \n      print(f"Loaded data with shape: {data_array.shape}")\n      print(f"Headers: {headers}")\n      \n      # If we have at least 2 columns, create a basic plot\n      if len(headers) >= 2:\n          try:\n              # Try to convert to numbers\n              x_data = [float(val) for val in data_array[:, 0]]\n              y_data = [float(val) for val in data_array[:, 1]]\n              \n              plt.figure(figsize=(10, 6))\n              plt.plot(x_data, y_data, \'bo-\', markersize=4, linewidth=1)\n              plt.title(f\'Data from {file_path.split("/")[-1]}\')\n              plt.xlabel(headers[0])\n              plt.ylabel(headers[1])\n              plt.grid(True, alpha=0.3)\n              plt.tight_layout()\n              plt.show()\n              \n          except ValueError:\n              print("Could not convert data to numbers. Showing first few rows:")\n              for i, row in enumerate(data[:5]):\n                  print(f"Row {i+1}: {row}")\n      \n  except Exception as e:\n      print(f"Error reading file: {e}")\n  \n  root.destroy()\n\n# Example: Create sample CSV data\ndef create_sample_csv():\n  """Create a sample CSV file for testing"""\n  filename = "sample_temperature_data.csv"\n  \n  # Generate sample temperature data\n  hours = range(24)\n  temperatures = [65 + 15 * np.sin((h - 6) * np.pi / 12) + \n                 np.random.normal(0, 2) for h in hours]\n  \n  with open(filename, \'w\', newline=\'\') as file:\n      writer = csv.writer(file)\n      writer.writerow([\'Hour\', \'Temperature_F\'])  # Headers\n      for hour, temp in zip(hours, temperatures):\n          writer.writerow([hour, f"{temp:.1f}"])\n  \n  print(f"Created sample file: {filename}")\n  return filename\n\n# Uncomment these lines to test:\n# create_sample_csv()\n# plot_csv_data()',tooltips:l.M2,theme:"dark",showLineNumbers:!0,copyButton:!0,className:"mb-6"}),(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:"/images/sample_temp_data_graph.png",alt:"image",title:"Plotted line graph with values from the created CSV sample file"})}),(0,a.jsx)("br",{}),(0,a.jsxs)(n.h2,{children:["Performing Statistical Analysis on Images  ",(0,a.jsx)("a",{id:"stat-analysis"})]}),(0,a.jsx)(n.p,{children:"Images contain a wealth of statistical information that can be analyzed and visualized. By combining OpenCV for image processing with\nMatPlotLib for visualization, we can gain insights into image characteristics, quality, and content."}),(0,a.jsx)(n.h3,{children:"Understanding Image Statistics"}),(0,a.jsx)(n.p,{children:"Every digital image can be analyzed statistically. The pixel values themselves are data points that can tell us about brightness, contrast,\ncolor distribution, and image quality."}),(0,a.jsx)(n.h3,{children:"Histogram Analysis"}),(0,a.jsx)(n.p,{children:"A histogram shows the distribution of pixel intensities in an image. It's one of the most fundamental tools in image analysis:"}),(0,a.jsx)(l.zI,{code:"import cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tkinter as tk\nfrom tkinter import filedialog\n\ndef analyze_image_histogram():\n  \"\"\"Load an image and analyze its histogram\"\"\"\n  root = tk.Tk()\n  root.withdraw()\n  \n  file_path = filedialog.askopenfilename(\n      title=\"Select an Image for Histogram Analysis\",\n      filetypes=[(\"Image files\", \"*.jpg *.jpeg *.png *.bmp *.tiff\")]\n  )\n  \n  if not file_path:\n      root.destroy()\n      return\n  \n  # Load the image\n  image = cv2.imread(file_path)\n  if image is None:\n      print(\"Could not load image!\")\n      root.destroy()\n      return\n  \n  # Convert BGR to RGB for matplotlib display\n  image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n  \n  # Create figure with subplots\n  fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n  \n  # Display original image\n  axes[0, 0].imshow(image_rgb)\n  axes[0, 0].set_title('Original Image')\n  axes[0, 0].axis('off')\n  \n  # Calculate and plot color histograms\n  colors = ['red', 'green', 'blue']\n  for i, color in enumerate(colors):\n      hist = cv2.calcHist([image], [i], None, [256], [0, 256])\n      axes[0, 1].plot(hist, color=color, alpha=0.7, linewidth=2)\n  \n  axes[0, 1].set_title('RGB Histogram')\n  axes[0, 1].set_xlabel('Pixel Intensity')\n  axes[0, 1].set_ylabel('Frequency')\n  axes[0, 1].legend(['Red', 'Green', 'Blue'])\n  axes[0, 1].grid(True, alpha=0.3)\n  \n  # Convert to grayscale and analyze\n  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n  \n  # Display grayscale image\n  axes[1, 0].imshow(gray, cmap='gray')\n  axes[1, 0].set_title('Grayscale Version')\n  axes[1, 0].axis('off')\n  \n  # Grayscale histogram\n  hist_gray = cv2.calcHist([gray], [0], None, [256], [0, 256])\n  axes[1, 1].plot(hist_gray, color='black', linewidth=2)\n  axes[1, 1].set_title('Grayscale Histogram')\n  axes[1, 1].set_xlabel('Pixel Intensity')\n  axes[1, 1].set_ylabel('Frequency')\n  axes[1, 1].grid(True, alpha=0.3)\n  \n  # Add statistics\n  mean_intensity = np.mean(gray)\n  std_intensity = np.std(gray)\n  axes[1, 1].axvline(x=mean_intensity, color='red', linestyle='--', \n                    label=f'Mean: {mean_intensity:.1f}')\n  axes[1, 1].axvline(x=mean_intensity + std_intensity, color='orange', \n                    linestyle='--', alpha=0.7, label=f'+1 Std: {mean_intensity + std_intensity:.1f}')\n  axes[1, 1].axvline(x=mean_intensity - std_intensity, color='orange', \n                    linestyle='--', alpha=0.7, label=f'-1 Std: {mean_intensity - std_intensity:.1f}')\n  axes[1, 1].legend()\n  \n  plt.tight_layout()\n  plt.show()\n  \n  # Print analysis\n  print(f\"\n=== Image Analysis ===\")\n  print(f\"Image size: {image.shape[1]} x {image.shape[0]} pixels\")\n  print(f\"Mean brightness: {mean_intensity:.2f}\")\n  print(f\"Standard deviation: {std_intensity:.2f}\")\n  print(f\"Brightness range: {np.min(gray)} to {np.max(gray)}\")\n  \n  # Determine image characteristics\n  if mean_intensity < 85:\n      print(\"This appears to be a dark image\")\n  elif mean_intensity > 170:\n      print(\"This appears to be a bright image\")\n  else:\n      print(\"This appears to be a well-balanced image\")\n  \n  if std_intensity < 30:\n      print(\"Low contrast image (narrow intensity range)\")\n  elif std_intensity > 70:\n      print(\"High contrast image (wide intensity range)\")\n  else:\n      print(\"Moderate contrast image\")\n  \n  root.destroy()\n\n# Run the analysis\nanalyze_image_histogram()",tooltips:l.M2,theme:"dark",showLineNumbers:!0,copyButton:!0,className:"mb-6"}),(0,a.jsx)(n.p,{children:"Output:"}),(0,a.jsx)(p.A,{children:(0,a.jsx)(n.p,{children:"=== Image Analysis ===\nImage size: 206 x 245 pixels\nMean brightness: 149.00\nStandard deviation: 103.22\nBrightness range: 0 to 255\nThis appears to be a well-balanced image"})}),(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:"/images/pfw_histogram.png",alt:"image",title:"A histogram of the Purdue University Fort Wayne logo"})}),(0,a.jsx)(n.h3,{children:"Edge Detection Analysis"}),(0,a.jsx)(n.p,{children:"Edge detection reveals the structure and features in an image. We can analyze and visualize edge information:"}),(0,a.jsx)(l.zI,{code:"import cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tkinter as tk\nfrom tkinter import filedialog\n\ndef analyze_image_edges():\n  \"\"\"Analyze edge information in an image\"\"\"\n  root = tk.Tk()\n  root.withdraw()\n  \n  file_path = filedialog.askopenfilename(\n      title=\"Select an Image for Edge Analysis\",\n      filetypes=[(\"Image files\", \"*.jpg *.jpeg *.png *.bmp *.tiff\")]\n  )\n  \n  if not file_path:\n      root.destroy()\n      return\n  \n  # Load and process image\n  image = cv2.imread(file_path)\n  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n  image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n  \n  # Apply different edge detection methods\n  edges_canny = cv2.Canny(gray, 50, 150)\n  edges_sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n  edges_sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n  edges_sobel = np.sqrt(edges_sobel_x**2 + edges_sobel_y**2)\n  \n  # Create visualization\n  fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n  \n  # Original image\n  axes[0, 0].imshow(image_rgb)\n  axes[0, 0].set_title('Original Image')\n  axes[0, 0].axis('off')\n  \n  # Grayscale\n  axes[0, 1].imshow(gray, cmap='gray')\n  axes[0, 1].set_title('Grayscale')\n  axes[0, 1].axis('off')\n  \n  # Canny edges\n  axes[0, 2].imshow(edges_canny, cmap='gray')\n  axes[0, 2].set_title('Canny Edge Detection')\n  axes[0, 2].axis('off')\n  \n  # Sobel X\n  axes[1, 0].imshow(np.abs(edges_sobel_x), cmap='gray')\n  axes[1, 0].set_title('Sobel X (Vertical Edges)')\n  axes[1, 0].axis('off')\n  \n  # Sobel Y\n  axes[1, 1].imshow(np.abs(edges_sobel_y), cmap='gray')\n  axes[1, 1].set_title('Sobel Y (Horizontal Edges)')\n  axes[1, 1].axis('off')\n  \n  # Sobel Combined\n  axes[1, 2].imshow(edges_sobel, cmap='gray')\n  axes[1, 2].set_title('Sobel Combined')\n  axes[1, 2].axis('off')\n  \n  plt.tight_layout()\n  plt.show()\n  \n  # Statistical analysis of edges\n  total_pixels = gray.shape[0] * gray.shape[1]\n  edge_pixels_canny = np.sum(edges_canny > 0)\n  edge_percentage = (edge_pixels_canny / total_pixels) * 100\n  \n  print(f\"\n=== Edge Analysis ===\")\n  print(f\"Total pixels: {total_pixels}\")\n  print(f\"Edge pixels (Canny): {edge_pixels_canny}\")\n  print(f\"Edge percentage: {edge_percentage:.2f}%\")\n  \n  if edge_percentage < 5:\n      print(\"Low detail image (smooth textures, few edges)\")\n  elif edge_percentage > 15:\n      print(\"High detail image (complex textures, many edges)\")\n  else:\n      print(\"Moderate detail image\")\n  \n  # Create edge density plot\n  plt.figure(figsize=(12, 5))\n  \n  # Plot 1: Edge density across rows\n  plt.subplot(1, 2, 1)\n  row_edges = np.sum(edges_canny, axis=1)\n  plt.plot(row_edges)\n  plt.title('Edge Density by Row')\n  plt.xlabel('Row Number')\n  plt.ylabel('Number of Edge Pixels')\n  plt.grid(True, alpha=0.3)\n  \n  # Plot 2: Edge density across columns\n  plt.subplot(1, 2, 2)\n  col_edges = np.sum(edges_canny, axis=0)\n  plt.plot(col_edges)\n  plt.title('Edge Density by Column')\n  plt.xlabel('Column Number')\n  plt.ylabel('Number of Edge Pixels')\n  plt.grid(True, alpha=0.3)\n  \n  plt.tight_layout()\n  plt.show()\n  \n  root.destroy()\n\n# Run the edge analysis\nanalyze_image_edges()",tooltips:l.M2,theme:"dark",showLineNumbers:!0,copyButton:!0,className:"mb-6"}),(0,a.jsx)(n.p,{children:"Output:"}),(0,a.jsx)(p.A,{children:(0,a.jsx)(n.p,{children:"=== Edge Analysis ===\nTotal pixels: 50470\nEdge pixels (Canny): 8291\nEdge percentage: 16.43%\nHigh detail image (complex textures, many edges)"})}),(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.img,{src:"/images/pfw_edge_detection.png",alt:"image",title:"An edge detection analysis on the Purdue Fort Wayne logo"}),"\n",(0,a.jsx)(n.img,{src:"/images/pfw_edge_density.png",alt:"image",title:"Analysis of the edge density by row and column of the Purdue Fort Wayne logo"})]}),(0,a.jsx)(n.h3,{children:"Color Analysis and Visualization"}),(0,a.jsx)(n.p,{children:"Analyzing color distribution can reveal important characteristics about images:"}),(0,a.jsx)(l.zI,{code:"import cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tkinter as tk\nfrom tkinter import filedialog\n\ndef analyze_image_colors():\n  \"\"\"Comprehensive color analysis of an image\"\"\"\n  root = tk.Tk()\n  root.withdraw()\n  \n  file_path = filedialog.askopenfilename(\n      title=\"Select an Image for Color Analysis\",\n      filetypes=[(\"Image files\", \"*.jpg *.jpeg *.png *.bmp *.tiff\")]\n  )\n  \n  if not file_path:\n      root.destroy()\n      return\n  \n  # Load image\n  image = cv2.imread(file_path)\n  image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n  image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n  \n  # Create comprehensive analysis\n  fig = plt.figure(figsize=(20, 15))\n  \n  # Original image\n  ax1 = plt.subplot(3, 4, 1)\n  plt.imshow(image_rgb)\n  plt.title('Original Image')\n  plt.axis('off')\n  \n  # Individual RGB channels\n  channels = ['Red', 'Green', 'Blue']\n  colors = ['Reds', 'Greens', 'Blues']\n  \n  for i in range(3):\n      ax = plt.subplot(3, 4, i + 2)\n      channel = image_rgb[:, :, i]\n      plt.imshow(channel, cmap=colors[i])\n      plt.title(f'{channels[i]} Channel')\n      plt.axis('off')\n  \n  # RGB Histogram\n  ax5 = plt.subplot(3, 4, 5)\n  for i, color in enumerate(['red', 'green', 'blue']):\n      hist = cv2.calcHist([image], [i], None, [256], [0, 256])\n      plt.plot(hist, color=color, alpha=0.7, linewidth=2)\n  plt.title('RGB Histogram')\n  plt.xlabel('Pixel Intensity')\n  plt.ylabel('Frequency')\n  plt.grid(True, alpha=0.3)\n  \n  # HSV Analysis\n  hue = image_hsv[:, :, 0]\n  saturation = image_hsv[:, :, 1]\n  value = image_hsv[:, :, 2]\n  \n  # Hue histogram (color wheel analysis)\n  ax6 = plt.subplot(3, 4, 6)\n  hist_hue = cv2.calcHist([image_hsv], [0], None, [180], [0, 180])\n  plt.plot(hist_hue, color='purple', linewidth=2)\n  plt.title('Hue Distribution')\n  plt.xlabel('Hue Value (0-179)')\n  plt.ylabel('Frequency')\n  plt.grid(True, alpha=0.3)\n  \n  # Saturation histogram\n  ax7 = plt.subplot(3, 4, 7)\n  hist_sat = cv2.calcHist([image_hsv], [1], None, [256], [0, 256])\n  plt.plot(hist_sat, color='orange', linewidth=2)\n  plt.title('Saturation Distribution')\n  plt.xlabel('Saturation Value (0-255)')\n  plt.ylabel('Frequency')\n  plt.grid(True, alpha=0.3)\n  \n  # Value/Brightness histogram\n  ax8 = plt.subplot(3, 4, 8)\n  hist_val = cv2.calcHist([image_hsv], [2], None, [256], [0, 256])\n  plt.plot(hist_val, color='gray', linewidth=2)\n  plt.title('Brightness Distribution')\n  plt.xlabel('Brightness Value (0-255)')\n  plt.ylabel('Frequency')\n  plt.grid(True, alpha=0.3)\n  \n  # Color dominance pie chart\n  ax9 = plt.subplot(3, 4, 9)\n  \n  # Calculate average color values\n  avg_red = np.mean(image_rgb[:, :, 0])\n  avg_green = np.mean(image_rgb[:, :, 1])\n  avg_blue = np.mean(image_rgb[:, :, 2])\n  \n  colors_pie = [avg_red, avg_green, avg_blue]\n  colors_names = ['Red', 'Green', 'Blue']\n  colors_hex = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n  \n  plt.pie(colors_pie, labels=colors_names, colors=colors_hex, autopct='%1.1f%%', startangle=90)\n  plt.title('Average Color Distribution')\n  \n  # 2D Histogram (Hue vs Saturation)\n  ax10 = plt.subplot(3, 4, 10)\n  plt.hist2d(hue.flatten(), saturation.flatten(), bins=50, cmap='viridis')\n  plt.title('Hue vs Saturation')\n  plt.xlabel('Hue')\n  plt.ylabel('Saturation')\n  plt.colorbar(label='Frequency')\n  \n  # Color temperature analysis\n  ax11 = plt.subplot(3, 4, 11)\n  \n  # Calculate color temperature indicator\n  blue_avg = np.mean(image_rgb[:, :, 2])\n  red_avg = np.mean(image_rgb[:, :, 0])\n  color_temp_ratio = blue_avg / (red_avg + 1)  # +1 to avoid division by zero\n  \n  temp_categories = ['Very Warm', 'Warm', 'Neutral', 'Cool', 'Very Cool']\n  temp_values = [0.8, 0.9, 1.0, 1.1, 1.2]\n  temp_colors = ['#FF4444', '#FF8844', '#FFFF44', '#44FFFF', '#4444FF']\n  \n  bars = plt.bar(temp_categories, temp_values, color=temp_colors, alpha=0.7)\n  plt.axhline(y=color_temp_ratio, color='red', linestyle='--', linewidth=3, label=f'This image: {color_temp_ratio:.2f}')\n  plt.title('Color Temperature Analysis')\n  plt.ylabel('Blue/Red Ratio')\n  plt.legend()\n  plt.xticks(rotation=45)\n  \n  # Dominant colors extraction\n  ax12 = plt.subplot(3, 4, 12)\n  \n  # Reshape image for k-means clustering\n  pixel_data = image_rgb.reshape(-1, 3)\n  \n  # Simple dominant color extraction (top 5 colors)\n  from collections import Counter\n  \n  # Reduce color space for easier analysis\n  reduced_pixels = pixel_data // 32 * 32  # Quantize to reduce similar colors\n  pixel_tuples = [tuple(pixel) for pixel in reduced_pixels]\n  color_counts = Counter(pixel_tuples)\n  \n  # Get top 5 most common colors\n  top_colors = color_counts.most_common(5)\n  \n  # Create color palette\n  colors_palette = [color[0] for color in top_colors]\n  counts_palette = [color[1] for color in top_colors]\n  \n  # Normalize colors for display\n  colors_normalized = [[c/255.0 for c in color] for color in colors_palette]\n  \n  bars = plt.bar(range(len(colors_palette)), counts_palette, color=colors_normalized)\n  plt.title('Top 5 Dominant Colors')\n  plt.xlabel('Color Rank')\n  plt.ylabel('Pixel Count')\n  \n  # Add color values as text\n  for i, (bar, color) in enumerate(zip(bars, colors_palette)):\n      plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(counts_palette)*0.01,\n              f'RGB({color[0]},{color[1]},{color[2]})', \n              ha='center', va='bottom', fontsize=8, rotation=90)\n  \n  plt.tight_layout()\n  plt.show()\n  \n  # Print comprehensive analysis\n  print(f\"\n=== Comprehensive Color Analysis ===\")\n  print(f\"Image dimensions: {image_rgb.shape[1]} x {image_rgb.shape[0]} pixels\")\n  print(f\"Total pixels: {image_rgb.shape[0] * image_rgb.shape[1]}\")\n  \n  print(f\"\n--- RGB Statistics ---\")\n  print(f\"Average Red: {avg_red:.1f}\")\n  print(f\"Average Green: {avg_green:.1f}\")\n  print(f\"Average Blue: {avg_blue:.1f}\")\n  \n  print(f\"\n--- HSV Statistics ---\")\n  print(f\"Average Hue: {np.mean(hue):.1f}\")\n  print(f\"Average Saturation: {np.mean(saturation):.1f}\")\n  print(f\"Average Brightness: {np.mean(value):.1f}\")\n  \n  # Color temperature analysis\n  if color_temp_ratio < 0.9:\n      print(f\"\n--- Color Temperature: WARM ---\")\n      print(\"This image has warm tones (more red/yellow)\")\n  elif color_temp_ratio > 1.1:\n      print(f\"\n--- Color Temperature: COOL ---\")\n      print(\"This image has cool tones (more blue)\")\n  else:\n      print(f\"\n--- Color Temperature: NEUTRAL ---\")\n      print(\"This image has balanced color temperature\")\n  \n  # Saturation analysis\n  avg_saturation = np.mean(saturation)\n  if avg_saturation < 100:\n      print(f\"\n--- Saturation: LOW ---\")\n      print(\"This image appears muted or desaturated\")\n  elif avg_saturation > 180:\n      print(f\"\n--- Saturation: HIGH ---\")\n      print(\"This image has very vibrant, saturated colors\")\n  else:\n      print(f\"\n--- Saturation: MODERATE ---\")\n      print(\"This image has normal color saturation\")\n  \n  print(f\"\n--- Dominant Colors ---\")\n  for i, (color, count) in enumerate(top_colors):\n      percentage = (count / (image_rgb.shape[0] * image_rgb.shape[1])) * 100\n      print(f\"#{i+1}: RGB{color} - {percentage:.1f}% of image\")\n  \n  root.destroy()\n\n# Run the comprehensive color analysis\nanalyze_image_colors()",tooltips:l.M2,theme:"dark",showLineNumbers:!0,copyButton:!0,className:"mb-6"}),(0,a.jsx)(n.p,{children:"Output:"}),(0,a.jsxs)(p.A,{children:[(0,a.jsx)(n.p,{children:"=== Comprehensive Color Analysis ===\nImage dimensions: 206 x 245 pixels\nTotal pixels: 50470"}),(0,a.jsx)(n.p,{children:"--- RGB Statistics ---\nAverage Red: 150.8\nAverage Green: 148.9\nAverage Blue: 144.4"}),(0,a.jsx)(n.p,{children:"--- HSV Statistics ---\nAverage Hue: 22.1\nAverage Saturation: 39.9\nAverage Brightness: 159.9"}),(0,a.jsx)(n.p,{children:"--- Color Temperature: NEUTRAL ---\nThis image has balanced color temperature"}),(0,a.jsx)(n.p,{children:"--- Saturation: LOW ---\nThis image appears muted or desaturated"}),(0,a.jsx)(n.p,{children:"--- Dominant Colors ---\n#1: RGB(np.uint8(224), np.uint8(224), np.uint8(224)) - 34.0% of image\n#2: RGB(np.uint8(0), np.uint8(0), np.uint8(0)) - 23.4% of image\n#3: RGB(np.uint8(192), np.uint8(192), np.uint8(192)) - 13.7% of image\n#4: RGB(np.uint8(128), np.uint8(128), np.uint8(128)) - 6.8% of image\n#5: RGB(np.uint8(192), np.uint8(128), np.uint8(0)) - 6.6% of image"})]}),(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:"/images/color_analysis.png",alt:"image",title:"A comprehensive color analysis of the Purdue University Fort Wayne logo"})}),(0,a.jsx)(n.h3,{children:"Image Quality Assessment"}),(0,a.jsx)(n.p,{children:"We can also analyze images to assess their technical quality:"}),(0,a.jsx)(l.zI,{code:"import cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tkinter as tk\nfrom tkinter import filedialog\n\ndef assess_image_quality():\n  \"\"\"Assess various quality metrics of an image\"\"\"\n  root = tk.Tk()\n  root.withdraw()\n  \n  file_path = filedialog.askopenfilename(\n      title=\"Select an Image for Quality Assessment\",\n      filetypes=[(\"Image files\", \"*.jpg *.jpeg *.png *.bmp *.tiff\")]\n  )\n  \n  if not file_path:\n      root.destroy()\n      return\n  \n  # Load image\n  image = cv2.imread(file_path)\n  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n  image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n  \n  # Calculate various quality metrics\n  \n  # 1. Sharpness (using Laplacian variance)\n  laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n  \n  # 2. Contrast (standard deviation of pixel intensities)\n  contrast = np.std(gray)\n  \n  # 3. Brightness (mean pixel intensity)\n  brightness = np.mean(gray)\n  \n  # 4. Noise estimation (using high-frequency components)\n  # Apply Gaussian blur and subtract from original\n  blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n  noise_estimate = np.std(gray.astype(np.float64) - blurred.astype(np.float64))\n  \n  # 5. Dynamic range\n  dynamic_range = np.max(gray) - np.min(gray)\n  \n  # 6. Histogram analysis for exposure\n  hist = cv2.calcHist([gray], [0], None, [256], [0, 256])\n  \n  # Check for clipping (overexposure/underexposure)\n  underexposed_pixels = hist[0:10].sum()\n  overexposed_pixels = hist[246:256].sum()\n  total_pixels = gray.shape[0] * gray.shape[1]\n  \n  underexposed_percent = (underexposed_pixels / total_pixels) * 100\n  overexposed_percent = (overexposed_pixels / total_pixels) * 100\n  \n  # Create quality assessment visualization\n  fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n  \n  # Original image\n  axes[0, 0].imshow(image_rgb)\n  axes[0, 0].set_title('Original Image')\n  axes[0, 0].axis('off')\n  \n  # Sharpness visualization (Laplacian)\n  laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n  axes[0, 1].imshow(np.abs(laplacian), cmap='gray')\n  axes[0, 1].set_title(f'Sharpness Map\n(Laplacian Variance: {laplacian_var:.0f})')\n  axes[0, 1].axis('off')\n  \n  # Histogram with quality indicators\n  axes[0, 2].plot(hist, color='black', linewidth=2)\n  axes[0, 2].axvline(x=brightness, color='blue', linestyle='--', linewidth=2, label=f'Mean: {brightness:.1f}')\n  axes[0, 2].axvspan(0, 10, alpha=0.3, color='red', label=f'Underexposed: {underexposed_percent:.1f}%')\n  axes[0, 2].axvspan(246, 255, alpha=0.3, color='yellow', label=f'Overexposed: {overexposed_percent:.1f}%')\n  axes[0, 2].set_title('Exposure Analysis')\n  axes[0, 2].set_xlabel('Pixel Intensity')\n  axes[0, 2].set_ylabel('Frequency')\n  axes[0, 2].legend()\n  axes[0, 2].grid(True, alpha=0.3)\n  \n  # Noise visualization\n  noise_map = np.abs(gray.astype(np.float64) - blurred.astype(np.float64))\n  axes[1, 0].imshow(noise_map, cmap='hot')\n  axes[1, 0].set_title(f'Noise Estimation\n(Std Dev: {noise_estimate:.2f})')\n  axes[1, 0].axis('off')\n  \n  # Quality metrics bar chart\n  metrics = ['Sharpness', 'Contrast', 'Brightness', 'Dynamic Range', 'Noise Level']\n  values = [laplacian_var/100, contrast, brightness, dynamic_range, noise_estimate*10]  # Normalized for display\n  colors = ['green', 'blue', 'orange', 'purple', 'red']\n  \n  bars = axes[1, 1].bar(metrics, values, color=colors, alpha=0.7)\n  axes[1, 1].set_title('Quality Metrics Overview')\n  axes[1, 1].set_ylabel('Normalized Values')\n  axes[1, 1].tick_params(axis='x', rotation=45)\n  \n  # Add value labels on bars\n  for bar, value in zip(bars, [laplacian_var, contrast, brightness, dynamic_range, noise_estimate]):\n      axes[1, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(values)*0.01,\n                     f'{value:.1f}', ha='center', va='bottom', fontsize=10)\n  \n  # Overall quality score\n  axes[1, 2].axis('off')\n  \n  # Calculate overall quality score (0-100)\n  sharpness_score = min(100, laplacian_var / 5)  # Good if > 500\n  contrast_score = min(100, contrast / 0.8)  # Good if > 80\n  brightness_score = 100 - abs(brightness - 128) / 1.28  # Best around 128\n  exposure_score = 100 - (underexposed_percent + overexposed_percent) * 2  # Penalize clipping\n  noise_score = max(0, 100 - noise_estimate * 10)  # Lower noise is better\n  \n  overall_score = (sharpness_score + contrast_score + brightness_score + exposure_score + noise_score) / 5\n  \n  # Create quality gauge\n  quality_text = f\"\"\"\n  OVERALL QUALITY SCORE: {overall_score:.1f}/100\n  \n  Individual Scores:\n  • Sharpness: {sharpness_score:.1f}/100\n  • Contrast: {contrast_score:.1f}/100\n  • Brightness: {brightness_score:.1f}/100\n  • Exposure: {exposure_score:.1f}/100\n  • Noise: {noise_score:.1f}/100\n  \n  Technical Details:\n  • Laplacian Variance: {laplacian_var:.0f}\n  • Contrast (StdDev): {contrast:.1f}\n  • Mean Brightness: {brightness:.1f}\n  • Dynamic Range: {dynamic_range}\n  • Noise Level: {noise_estimate:.2f}\n  \"\"\"\n  \n  axes[1, 2].text(0.1, 0.9, quality_text, transform=axes[1, 2].transAxes, \n                 fontsize=12, verticalalignment='top', fontfamily='monospace',\n                 bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightgray\", alpha=0.8))\n  \n  plt.tight_layout()\n  plt.show()\n  \n  # Print detailed assessment\n  print(f\"\n=== IMAGE QUALITY ASSESSMENT ===\")\n  print(f\"File: {file_path.split('/')[-1]}\")\n  print(f\"Dimensions: {image.shape[1]} x {image.shape[0]} pixels\")\n  \n  print(f\"\n--- Sharpness Analysis ---\")\n  if laplacian_var > 500:\n      print(f\"✓ SHARP: Laplacian variance = {laplacian_var:.0f} (Good: >500)\")\n  elif laplacian_var > 100:\n      print(f\"~ MODERATE: Laplacian variance = {laplacian_var:.0f} (Acceptable: 100-500)\")\n  else:\n      print(f\"✗ BLURRY: Laplacian variance = {laplacian_var:.0f} (Poor: <100)\")\n  \n  print(f\"\n--- Contrast Analysis ---\")\n  if contrast > 80:\n      print(f\"✓ HIGH CONTRAST: Standard deviation = {contrast:.1f} (Good: >80)\")\n  elif contrast > 40:\n      print(f\"~ MODERATE CONTRAST: Standard deviation = {contrast:.1f} (Acceptable: 40-80)\")\n  else:\n      print(f\"✗ LOW CONTRAST: Standard deviation = {contrast:.1f} (Poor: <40)\")\n  \n  print(f\"\n--- Exposure Analysis ---\")\n  if underexposed_percent > 5:\n      print(f\"⚠ UNDEREXPOSED: {underexposed_percent:.1f}% of pixels are very dark\")\n  if overexposed_percent > 5:\n      print(f\"⚠ OVEREXPOSED: {overexposed_percent:.1f}% of pixels are blown out\")\n  if underexposed_percent <= 5 and overexposed_percent <= 5:\n      print(f\"✓ WELL EXPOSED: Minimal clipping in shadows and highlights\")\n  \n  print(f\"\n--- Noise Analysis ---\")\n  if noise_estimate < 5:\n      print(f\"✓ LOW NOISE: Noise level = {noise_estimate:.2f} (Good: <5)\")\n  elif noise_estimate < 15:\n      print(f\"~ MODERATE NOISE: Noise level = {noise_estimate:.2f} (Acceptable: 5-15)\")\n  else:\n      print(f\"✗ HIGH NOISE: Noise level = {noise_estimate:.2f} (Poor: >15)\")\n  \n  print(f\"\n--- Overall Assessment ---\")\n  if overall_score >= 80:\n      print(f\"✓ EXCELLENT QUALITY: Score = {overall_score:.1f}/100\")\n  elif overall_score >= 60:\n      print(f\"✓ GOOD QUALITY: Score = {overall_score:.1f}/100\")\n  elif overall_score >= 40:\n      print(f\"~ FAIR QUALITY: Score = {overall_score:.1f}/100\")\n  else:\n      print(f\"✗ POOR QUALITY: Score = {overall_score:.1f}/100\")\n  \n  root.destroy()\n\n# Run the quality assessment\nassess_image_quality()",tooltips:l.M2,theme:"dark",showLineNumbers:!0,copyButton:!0,className:"mb-6"}),(0,a.jsx)(n.p,{children:"Output:"}),(0,a.jsxs)(p.A,{children:[(0,a.jsx)(n.p,{children:"=== IMAGE QUALITY ASSESSMENT ===\nFile: images.png\nDimensions: 206 x 245 pixels"}),(0,a.jsx)(n.p,{children:"--- Sharpness Analysis ---\n✓ SHARP: Laplacian variance = 12855 (Good: >500)"}),(0,a.jsx)(n.p,{children:"--- Contrast Analysis ---\n✓ HIGH CONTRAST: Standard deviation = 103.2 (Good: >80)"}),(0,a.jsx)(n.p,{children:"--- Exposure Analysis ---\n⚠ UNDEREXPOSED: 22.7% of pixels are very dark\n⚠ OVEREXPOSED: 33.3% of pixels are blown out"}),(0,a.jsx)(n.p,{children:"--- Noise Analysis ---\n✗ HIGH NOISE: Noise level = 32.13 (Poor: >15)"}),(0,a.jsx)(n.p,{children:"--- Overall Assessment ---\n~ FAIR QUALITY: Score = 54.3/100"})]}),(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:"/images/pfw_quality_assessment.png",alt:"image",title:"An image quality assessment on the Purdue University Fort Wayne logo"})}),(0,a.jsx)(n.h3,{children:"Batch Analysis for Multiple Images"}),(0,a.jsx)(n.p,{children:"Sometimes you want to analyze multiple images and compare their characteristics:"}),(0,a.jsx)(l.zI,{code:"import cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tkinter as tk\nfrom tkinter import filedialog\nimport os\n\ndef batch_image_analysis():\n  \"\"\"Analyze multiple images and create comparison charts\"\"\"\n  root = tk.Tk()\n  root.withdraw()\n  \n  # Select multiple image files\n  file_paths = filedialog.askopenfilenames(\n      title=\"Select Multiple Images for Batch Analysis\",\n      filetypes=[(\"Image files\", \"*.jpg *.jpeg *.png *.bmp *.tiff\")]\n  )\n  \n  if not file_paths:\n      root.destroy()\n      return\n  \n  # Store results for all images\n  results = []\n  \n  print(f\"Analyzing {len(file_paths)} images...\")\n  \n  for i, file_path in enumerate(file_paths):\n      print(f\"Processing image {i+1}/{len(file_paths)}: {os.path.basename(file_path)}\")\n      \n      # Load and analyze image\n      image = cv2.imread(file_path)\n      if image is None:\n          print(f\"Could not load {file_path}, skipping...\")\n          continue\n      \n      gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n      \n      # Calculate metrics\n      brightness = np.mean(gray)\n      contrast = np.std(gray)\n      sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()\n      \n      # Color analysis\n      image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n      avg_red = np.mean(image_rgb[:, :, 0])\n      avg_green = np.mean(image_rgb[:, :, 1])\n      avg_blue = np.mean(image_rgb[:, :, 2])\n      \n      # File size\n      file_size = os.path.getsize(file_path) / 1024  # KB\n      \n      results.append({\n          'filename': os.path.basename(file_path),\n          'brightness': brightness,\n          'contrast': contrast,\n          'sharpness': sharpness,\n          'red': avg_red,\n          'green': avg_green,\n          'blue': avg_blue,\n          'file_size': file_size,\n          'width': image.shape[1],\n          'height': image.shape[0]\n      })\n  \n  if not results:\n      print(\"No images could be processed!\")\n      root.destroy()\n      return\n  \n  # Create comparison visualizations\n  fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n  \n  filenames = [r['filename'] for r in results]\n  \n  # Brightness comparison\n  brightness_values = [r['brightness'] for r in results]\n  axes[0, 0].bar(range(len(results)), brightness_values, color='orange', alpha=0.7)\n  axes[0, 0].set_title('Brightness Comparison')\n  axes[0, 0].set_ylabel('Average Brightness')\n  axes[0, 0].set_xticks(range(len(results)))\n  axes[0, 0].set_xticklabels([f[:10] + '...' if len(f) > 10 else f for f in filenames], rotation=45)\n  \n  # Contrast comparison\n  contrast_values = [r['contrast'] for r in results]\n  axes[0, 1].bar(range(len(results)), contrast_values, color='blue', alpha=0.7)\n  axes[0, 1].set_title('Contrast Comparison')\n  axes[0, 1].set_ylabel('Contrast (Std Dev)')\n  axes[0, 1].set_xticks(range(len(results)))\n  axes[0, 1].set_xticklabels([f[:10] + '...' if len(f) > 10 else f for f in filenames], rotation=45)\n  \n  # Sharpness comparison\n  sharpness_values = [r['sharpness'] for r in results]\n  axes[0, 2].bar(range(len(results)), sharpness_values, color='green', alpha=0.7)\n  axes[0, 2].set_title('Sharpness Comparison')\n  axes[0, 2].set_ylabel('Sharpness (Laplacian Var)')\n  axes[0, 2].set_xticks(range(len(results)))\n  axes[0, 2].set_xticklabels([f[:10] + '...' if len(f) > 10 else f for f in filenames], rotation=45)\n  \n  # Color comparison\n  red_values = [r['red'] for r in results]\n  green_values = [r['green'] for r in results]\n  blue_values = [r['blue'] for r in results]\n  \n  x = np.arange(len(results))\n  width = 0.25\n  \n  axes[1, 0].bar(x - width, red_values, width, label='Red', color='red', alpha=0.7)\n  axes[1, 0].bar(x, green_values, width, label='Green', color='green', alpha=0.7)\n  axes[1, 0].bar(x + width, blue_values, width, label='Blue', color='blue', alpha=0.7)\n  axes[1, 0].set_title('Average Color Values')\n  axes[1, 0].set_ylabel('Average Channel Value')\n  axes[1, 0].set_xticks(x)\n  axes[1, 0].set_xticklabels([f[:10] + '...' if len(f) > 10 else f for f in filenames], rotation=45)\n  axes[1, 0].legend()\n  \n  # File size comparison\n  file_sizes = [r['file_size'] for r in results]\n  axes[1, 1].bar(range(len(results)), file_sizes, color='purple', alpha=0.7)\n  axes[1, 1].set_title('File Size Comparison')\n  axes[1, 1].set_ylabel('File Size (KB)')\n  axes[1, 1].set_xticks(range(len(results)))\n  axes[1, 1].set_xticklabels([f[:10] + '...' if len(f) > 10 else f for f in filenames], rotation=45)\n  \n  # Resolution comparison\n  resolutions = [r['width'] * r['height'] / 1000000 for r in results]  # Megapixels\n  axes[1, 2].bar(range(len(results)), resolutions, color='brown', alpha=0.7)\n  axes[1, 2].set_title('Resolution Comparison')\n  axes[1, 2].set_ylabel('Resolution (Megapixels)')\n  axes[1, 2].set_xticks(range(len(results)))\n  axes[1, 2].set_xticklabels([f[:10] + '...' if len(f) > 10 else f for f in filenames], rotation=45)\n  \n  plt.tight_layout()\n  plt.show()\n  \n  # Print summary statistics\n  print(f\"\n=== BATCH ANALYSIS SUMMARY ===\")\n  print(f\"Total images analyzed: {len(results)}\")\n  \n  print(f\"\n--- Brightness Statistics ---\")\n  print(f\"Brightest image: {filenames[brightness_values.index(max(brightness_values))]} ({max(brightness_values):.1f})\")\n  print(f\"Darkest image: {filenames[brightness_values.index(min(brightness_values))]} ({min(brightness_values):.1f})\")\n  print(f\"Average brightness: {np.mean(brightness_values):.1f}\")\n  \n  print(f\"\n--- Contrast Statistics ---\")\n  print(f\"Highest contrast: {filenames[contrast_values.index(max(contrast_values))]} ({max(contrast_values):.1f})\")\n  print(f\"Lowest contrast: {filenames[contrast_values.index(min(contrast_values))]} ({min(contrast_values):.1f})\")\n  print(f\"Average contrast: {np.mean(contrast_values):.1f}\")\n  \n  print(f\"\n--- Sharpness Statistics ---\")\n  print(f\"Sharpest image: {filenames[sharpness_values.index(max(sharpness_values))]} ({max(sharpness_values):.0f})\")\n  print(f\"Blurriest image: {filenames[sharpness_values.index(min(sharpness_values))]} ({min(sharpness_values):.0f})\")\n  print(f\"Average sharpness: {np.mean(sharpness_values):.0f}\")\n  \n  print(f\"\n--- File Size Statistics ---\")\n  print(f\"Largest file: {filenames[file_sizes.index(max(file_sizes))]} ({max(file_sizes):.1f} KB)\")\n  print(f\"Smallest file: {filenames[file_sizes.index(min(file_sizes))]} ({min(file_sizes):.1f} KB)\")\n  print(f\"Average file size: {np.mean(file_sizes):.1f} KB\")\n  \n  root.destroy()\n\n# Run the batch analysis\nbatch_image_analysis()",tooltips:l.M2,theme:"dark",showLineNumbers:!0,copyButton:!0,className:"mb-6"}),(0,a.jsx)(n.p,{children:"Output:"}),(0,a.jsxs)(p.A,{children:[(0,a.jsx)(n.p,{children:"=== BATCH ANALYSIS SUMMARY ===\nTotal images analyzed: 3"}),(0,a.jsxs)(n.p,{children:["--- Brightness Statistics ---",(0,a.jsx)(n.br,{}),"\n","Brightest image: pfw.png (149.0)\nDarkest image: pfw_don.jpg (52.9)\nAverage brightness: 106.6"]}),(0,a.jsx)(n.p,{children:"--- Contrast Statistics ---\nHighest contrast: pfw.png (103.2)\nLowest contrast: Mascot-Walb.jpg (51.5)\nAverage contrast: 71.6"}),(0,a.jsx)(n.p,{children:"--- Sharpness Statistics ---\nSharpest image: pfw.png (12855)\nBlurriest image: Mascot-Walb.jpg (2126)\nAverage sharpness: 5711"}),(0,a.jsx)(n.p,{children:"--- File Size Statistics ---\nLargest file: Mascot-Walb.jpg (45.5 KB)\nSmallest file: pfw_don.jpg (8.4 KB)\nAverage file size: 22.1 KB"})]}),(0,a.jsxs)(n.p,{children:["The batch analysis summary was run on these 3 images:\n",(0,a.jsx)(n.img,{src:"/images/pfw_examples.png",alt:"image",title:"Example images for the batch analysis"}),"\n",(0,a.jsx)(n.img,{src:"/images/pfw_batch_analysis.png",alt:"image",title:"Batch image analysis that was run on the above images"})]}),(0,a.jsx)("br",{}),(0,a.jsxs)(n.h2,{children:["Summary and Next Steps  ",(0,a.jsx)("a",{id:"summary-next-steps"})]}),(0,a.jsx)(n.p,{children:"MatPlotLib is an incredibly powerful tool for data visualization that becomes even more useful when combined with image processing libraries\nlike OpenCV. Through this tutorial, you've learned:"}),(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Basic Plotting Concepts"}),": Understanding axes, data relationships, and different chart types"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Data Collection Strategies"}),": How to gather data effectively without interrupting the program"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Image Statistical Analysis"}),": Extracting meaningful numerical data from images"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Quality Assessment"}),": Using statistical methods to evaluate image characteristics"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Batch Processing"}),": Analyzing multiple images at a time for comparison and pattern detection"]}),"\n"]}),(0,a.jsx)("br",{}),(0,a.jsx)(o.T0,{title:"Know the Best Way to Learn",children:(0,a.jsx)(n.p,{children:"Remember: the best way to learn data visualization is through practice. Start with your own images and data, experiment with different\nchart types, and don't be afraid to try new approaches. Every dataset has a story to tell - your job is to find the best way to visualize\nthat story!"})}),(0,a.jsx)("br",{}),(0,a.jsx)(n.h3,{children:"Links and Further Reading"}),(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"https://matplotlib.org/stable/tutorials/pyplot.html",children:(0,a.jsx)(n.strong,{children:"MatPlotLib Official Tutorial"})})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"https://matplotlib.org/stable/gallery/index.html",children:(0,a.jsx)(n.strong,{children:"MatPlotLib Gallery"})})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"https://docs.opencv.org/",children:(0,a.jsx)(n.strong,{children:"OpenCV Documentation"})})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"https://numpy.org/doc/stable/reference/routines.statistics.html",children:(0,a.jsx)(n.strong,{children:"NumPy Statistical Functions"})})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"https://opencv-python-tutroals.readthedocs.io/",children:(0,a.jsx)(n.strong,{children:"Image Processing Fundamentals"})})}),"\n"]})]})}function m(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{};return(0,a.jsx)(c,{...e,children:(0,a.jsx)(d,{...e})})}},9254:(e,n,t)=>{"use strict";t.d(n,{A:()=>s});var a=t(7876);function s(e){let{title:n="Terminal",children:t,className:s=""}=e;return(0,a.jsxs)("div",{className:"rounded-md border border-[#2e2e2e] bg-[#1e1e1e] text-[#d4d4d4] font-mono mb-3 ".concat(s),children:[(0,a.jsx)("div",{className:"flex justify-between items-center px-4 py-2.5 border-b border-[#2e2e2e] bg-[#2b2b2b]",children:(0,a.jsx)("span",{className:"text-sm text-[#dcdcdc]",children:n})}),(0,a.jsx)("pre",{className:"px-4 py-3 pb-1 pl-10 overflow-x-auto text-sm leading-relaxed whitespace-pre-wrap m-0",children:(0,a.jsx)("code",{className:"text-[#f0f0f0]",children:"string"==typeof t?t.trimEnd().split("\n").map((e,n)=>e.includes("Traceback")?(0,a.jsx)("div",{className:"text-yellow-400",children:e},n):e.includes("NameError")?(0,a.jsx)("div",{className:"text-red-500 font-semibold",children:e},n):(0,a.jsx)("div",{children:e},n)):t})})]})}}},e=>{var n=n=>e(e.s=n);e.O(0,[809,636,593,792],()=>n(6236)),_N_E=e.O()}]);